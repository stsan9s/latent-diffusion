model:
  base_learning_rate: 2.0e-06
  target: ldm.models.diffusion.classifier.NoisyLatentImageClassifier
  params:
    diffusion_path: models/ldm/ffhq256/
    # ckpt_path: None
    # label_key: None
    num_classes: 8
    diffusion_ckpt_path: models/ldm/ffhq256/model.ckpt
    # first_stage_config:
    #   target: ldm.models.autoencoder.VQModelInterface
    #   params:
    #     embed_dim: 3
    #     n_embed: 8192
    #     ckpt_path: configs/first_stage_models/vq-f4/model.yaml
    #     ddconfig:
    #       double_z: false
    #       z_channels: 3
    #       resolution: 256
    #       in_channels: 3
    #       out_ch: 3
    #       ch: 128
    #       ch_mult:
    #       - 1
    #       - 2
    #       - 4
    #       num_res_blocks: 2
    #       attn_resolutions: []
    #       dropout: 0.0
    #     lossconfig:
    #       target: torch.nn.Identity
    # cond_stage_config: __is_unconditional__
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 42
    num_workers: 5
    wrap: false
    train:
      target: taming.data.faceshq.FFHQTrainLabels
      params:
        size: 256
    validation:
      target: taming.data.faceshq.FFHQValidationLabels
      params:
        size: 256


lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        batch_frequency: 5000
        max_images: 8
        increase_log_steps: False

  trainer:
    benchmark: True
